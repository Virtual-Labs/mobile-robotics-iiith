<!-- This file needs to be edited by the lab developer to suit
the requirements of their lab in particular.-->

<!-- Add class="default" to include any element as it is
specified in default.html. 
Do not include class="default" to the elements that you want to
edit -->

<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>
<body>

<div id="experiment"> <!-- The Experiment Document Container-->

  <!-- The lab Header contains the logo and the name of the lab,
  usually displayed on the top of the page-->

  <header id="experiment-header" class="default">
  
    <div id="experiment-header-logo" class="logo">
      <!-- Enclose the logo image of your lab or write it in 
      text-->
      <img src="../images/logo.jpg" />
    </div>

    <div id="experiment-header-heading" class="heading">
      <!-- Write the name of your lab and link it to the home 
      page of your lab (h1 tag is preferred while writing your 
      lab name)-->
      <a href="../index.html">Mobile Robotics</a>	
    </div>

    <!-- Add any additional element you want to add to the lab 
    header, For example : Help (Enclosing them with suitable 
    div is recommended)-->

  </header>


  <!-- The lab article is the main content area where all the 
  experiment content sits-->
  <article id="experiment-article">
  
    <!-- The lab article has an header, optional navigational 
    menu, number of sections, an optional sidebar and a closing 
    footer-->
     <div id="experiment-article-breadcrumb" class="breadcrumb">
     </div>
    
      <header id="experiment-article-heading" class="heading">
        <!-- You can add a welcome message or title of the 
        experiment here -->
       	Scan Matching
        <!-- Add any additional element if required with proper 
        enclosing-->
      </header>

      <!-- Navigation menu is useful to organize the view of 
      multiple sections inside the article-->
      <nav id="experiment-article-navigation" class="default">
        <ul id="experiment-article-navigation-menu">
          <!-- The menu can be dynamically generated to contain 
          the headings of your sections or instead write the 
          menu items of your choice individually enclosedu in 
          <li> tag as shown below-->
        </ul>
      </nav>

      <!-- All the sections of your lab or experiment can be 
      enclosed together with a div element as shown below-->
      <div id="experiment-article-sections">

        <!-- First section of the article-->
        <section id="experiment-article-section-1">
          
          <div id="experiment-article-section-1-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab -->
	    <img src="../images/introduction.jpg" />
	  </div>	
          
          <!-- The heading for the section can be enclosed in a 
          div tag. -->
          <div id="experiment-article-section-1-heading" 
          class="heading">
            Introduction
          </div>

          <!-- Write the section content inside a paragraph 
          element, You can also include images with <img> tag -->
          <div id="experiment-article-section-1-content" 
          class="content">	
 
 <p><b>What is scan matching?</b></p>

<p>Scan matching is a process by which two data sets are aligned leading to an accurate estimate of the position of the robot. </p>

<p>These data sets are usually in the form of 2D laser range scans or 3D point clouds. </p>

<p>A point cloud is a set of 2D/3D points. The points usually defined by (X,Y) or (X,Y,Z) coordinates, are typically intended to be representative of the external surface of an object.</p>

<p> See the figure below for an example of 2D point cloud data.</p>

<p align="center">
	 <img style="height:400px; width:400px;" src="images_scanmatching/map.jpg">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	 <img style="height:400px; width:400px;" src="images_scanmatching/2dscan.jpg"><br>
</p>

<p> The figure on the left shows the real map while the one on the right shows the 2D point cloud. The robot is in black and the obstacles are marked. The 2D point cloud is in black. The 2D point cloud is a set of&nbsp; <b>(r,θ)</b> plotted in an XY plane as <b>(rcosθ,rsinθ)</b>.
The <b>r</b> is the range to an obstacle along the<b> θ</b> wrt to robot orientation.</p>



<p> So, basically in scan matching we take two different sets of scans from two different robot poses. Then we try to align them. This leads to an accurate estimate of the robot's new position. <b>How</b>, is discussed in the theory section? <br>
<br>
The two scans are essentially 2 different view points of the same environment. One representation differs from the other by a Rotation and a translation.
You can obtain the original position of the robot by doing an inverse of these transformations.
</p>

<p> In the figure below you can see the result of two different scans.</p>

<p align="center"><img style="width: 405px; height: 404px;" alt=""  src="images_scanmatching/error_scans.png"><br></p>


<p> They also appear translated or rotated due to an error or noise in the origin of the reference frame. This case is more apt to a robotic setting. For example let the predicted reference frame of the robot be <span style="font-weight: bold;"><font color="red">P</font></span>(in red color) while the actual reference frame be <b>A</b>(in black color) as shown in the figure on the left.</p>

<p> We have an initial scan taken from our actual position <b>A</b>. The position of <b>A</b> in a global co-ordinate system G is unknown. The black scan is the actual scan.</p> <p>The dots in the scan represent the obstacles. </p>

<br>
<p> Now, based on our estimate of where the robot is and the information of the actual scan, we project from our predicted pose the actual scan obtaining the projected scan (shown as red in the figure). From the orientation of the projected scan with respect to the original scan, we get, an idea of where the robot should have been for such a scan to have been taken. </p>

<p>If the position of <b>A</b> was known in the co-ordinate frame G, then the red scan would co-incide with the black scan, and <b><font color="red">P</font></b> would coincide with <b>A</b>. </p>

<p>But, since <b>A</b> is not known with respect to G, on projecting the actual (black) scan from <b><font color="red">P</font></b> we obtain the red scan. </p>

<p>
Using the difference in orientation and location of the 2 scans, scanmatching can then find the transformation from <b><font color="red">P</font></b> to <b>A</b> thereby correcting the error in the robot’s predicted pose. This error arises precisely due to errors in the robot’s motion.
<br>
</p>

<p align="center"><img style="width: 400px; height: 400px;" alt=""  src="images_scanmatching/error_robot.png"><img  style="width: 405px; height: 404px;" alt=""  src="images_scanmatching/error_scans.png" hspace="15"><br></p>

 <p>
<b>What are the causes of this error that leads to the robot identifying its pose with <font color="red">P</font> than with A?&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; 
</b><br>
</p>
 
<p>The reasons are quite a few, some of which are enumerated below:</p>

<p>
<b>a)</b> The left wheel and right wheel do not move with the same velocity while moving along a straight line leading to a drift in the robot motion even with
the best PID controller onboard the robot.
</p>

<p>
<b>b)</b> The left and
right wheel diameters are not precisely equal, which is one of the causes for <b>a</b>.<br>
</p>

<p>
<b>c)</b> The problem is accentuated when the robot rotates, for the robot is never able to rotate precisely to the commanded value. For example when asked to 
rotate 10 degrees it may turn by 9 or 11 degrees. The error in rotation followed by a translation leads to the robot to wrong locations rather than the desired/predicted poses.<br>
</p>
<br>

        </div>


      </section>

      <!-- Second section of the article-->
      <section id="experiment-article-section-2">
        
        <div id="experiment-article-section-2-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/theory.jpg" />
	</div>
				
        <!-- The heading for the section can be enclosed in a 
        div tag. -->
        <div id="experiment-article-section-2-heading" 
        class="heading">
          Theory
        </div>


        <!-- Write the section content inside a paragraph 
        element, we can also include images with <img> tag -->
        <div id="experiment-article-section-2-content" 
        class="content">

<p>So, from the two different robot poses we have two different scans</p>

<p>Let's call the initial scan <b>S<sub>A</sub></b> and the position it was taken from as <b>A</b>.</p>

<p>Similarly, let <b>S<sub>P</sub></b> and <b>P</b> represent the projected scan and the predicted pose respectively.</p>

<p>We can represent <b>A</b> in terms of <b>P</b> with the following equation:</p>
	
		<center><p>	<b>A = R x <font color="red">P</font> + T </b></p> </center>

		<p> Here, <b> R</b> is the rotation matrix and <b>T</b> is the translation vector.</p>
		
		<p> In the figure below, let <font color="red"><b>P</b></font> represent the predicted pose of the robot (in red) and <b>A</b> represent the actual position of the robot (in black).</p>
		
		<p align="center"><img style="height:400px; width:400px;" src="images_scanmatching/error_robot.png">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img style="height:400px; width:400px;" src="images_scanmatching/real_scan.png"></p>
		
		<br>
	<p>Now, what we seek to find is the values of <b>R</b> and <b>T</b> that minimize the expression |<b>A</b>-<font color="red"><b>P</b></font>|<sup>2</sup>.</p>
	
	<p> Solving for these minimization results  we get:</p>
	
	<p align="center"><img style="height:55px; width:770px;" src="images_scanmatching/sol.jpg"></p>
	<br>
	<br>
	<p align="center">
	<img style="height:39px; width:250px;" src="images_scanmatching/cov1.jpg"> is the covariance of the x-coordinates of points in the  red scan (predicted scan) and y co-ordinates of points in the black scan(actual scan from the predicted pose). The summation is over  the n <b>corresponding points</b>.</p>
		
<p>Similarly <img style=" height:39px; width:250px;" src="images_scanmatching/cov2.jpg">and so on and so forth. The bar over the x or y represents the mean of that component over n values.</p>
	
<br>
<p><b>But, how do we know which points in each of the scans refer to the same object?</b></p>

<p>There are correspondence rules to determine which 2 points in the 2 scans are related. We explain only one here. It is also the one used in the Virtual Lab. </p>

<p><b>Closest-Point Rule</b></p>
<p>For each point in our new scan we iterate through all the points in our initial scan and find the one closest to it. </p>
	
        </div>
      </section>


      <section id="experiment-article-section-3">
        
        <div id="experiment-article-section-3-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab. -->
	  <img src="../images/objective.jpg" />
	</div>
     
        <div id="experiment-article-section-3-heading" 
        class="heading">
          Objective
        </div>

        <div id="experiment-article-section-3-content" 
        class="content">

<p> The objective of this virtual lab experiment is to find the transformation between the actual and predicted pose of the robot by matching the predicted range scan and the actual range scan through a scan matching formulation. The reasons for the accrued error between the predicted and actual pose are due to the reasons covered in Introduction. The transformations are in a plane, which means that the rotation is only due to yaw of the robot (rotation about the z axis) and the translations are only along x and y.<br> </p>

        </div>

      </section>

        <section id="experiment-article-section-7">
	  
          <div id="experiment-article-section-7-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab. -->
	    <img src="../images/procedure.jpg" />
	  </div>
	
          <div id="experiment-article-section-7-heading" 
          class="heading">
	    Procedure
	  </div>
	
          <div id="experiment-article-section-7-content" 
          class="content">
<p>
<b>Information on how to use the Experiment:</b> </p>

<p>1. Multiple maps are provide here.</p>

<p>
2. 2D laser range finder is used here.<br>
</p>

<p align="center"><img style="width: 500px; height: 360px;" alt="" src="images_scanmatching/explanation.jpg"><br></p>

<p>3.Refer to image above showing the two panels used to display data.</p><br>

<p>4. Color legend for Panel 1</p><br>

<table style="text-align: left; width: 351px; height: 88px;" border="1"
 cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top;">Black<br></td>
      <td style="vertical-align: top;">Real Position<br></td>
    </tr>
    
    <tr>
      <td style="vertical-align: top;">Red<br></td>
      <td style="vertical-align: top;">Predicted Position(Real Postion + Error)<br></td>
    </tr>
    
    <tr>
      <td style="vertical-align: top;">Green<br></td>
      <td style="vertical-align: top;">Corrected  Position<br></td>
    </tr>
    
  </tbody>
</table>


<p>5. Similarly in Panel 2 same colors used to show corresponding range scans.</p><br>

<table style="text-align: left; width: 352px; height: 88px;" border="1"
 cellpadding="2" cellspacing="2">
  <tbody>
    <tr>
      <td style="vertical-align: top;">Black<br></td>
      <td style="vertical-align: top;">Scan from Real Postion<br></td>
    </tr>
    
    <tr>
      <td style="vertical-align: top;">Red<br></td>
      <td style="vertical-align: top;">Scan from Predicted Position<br></td>
    </tr>
    
    <tr>
      <td style="vertical-align: top;">Green<br></td>
      <td style="vertical-align: top;">Scan from Corrected Position<br></td>
    </tr>
  </tbody>
</table>

<p>6. Use the three slider bars to set the corresponding error in (x,y,θ) of Robot predicted pose.<br></p>
 
<p>7. Certain Predefined cases are also given. Else click on the panel 1 to set Robot real pose.</p>

<p> 8. Then hit Run to display the results.<br> </p>

<p> 9. Now you can use the slider bar to display results after certain number of iterations of the scan matching algorithm.</p>

<p> 10.As you move the slider from 0 to 10 you find how the green corrected scan moves from red to black simultaneously as the robot pose gets corrected from the predicted position (red circle) to the actual position (black circle). The corrected robot position is shown as the center of the green circle.
	  </div>
	
        </section>




      <section id="experiment-article-section-4">

        <div id="experiment-article-section-4-icon" 
        class="icon">
	  <!-- Enclose the icon image of your lab.-->
	  <img src="../images/simulation.jpg" />
	</div>

        <div id="experiment-article-section-4-heading" 
        class="heading">
          Experiment
        </div>

        <div id="experiment-article-section-4-content" 
        class="content">
        <p>
<applet code="NewApplet.class" archive="ScanMatchingDev.jar" height="600" width="800"></applet>
</p>

      
        </div>

      </section>

<!--      <section id="experiment-article-section-5">
   
        <div id="experiment-article-section-5-icon" 
        class="icon">
	
	  <img src="../images/manual.jpg" />
	</div>

        <div id="experiment-article-section-5-heading" 
        class="heading">
          Manual
        </div>

        <div id="experiment-article-section-5-content" 
        class="content">
		<p>Nothing Here.</p>
          </div>

        </section>-->

        <section id="experiment-article-section-6">
      
          <div id="experiment-article-section-6-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab.-->
	    <img src="../images/quizzes.jpg" />
	  </div>

          <div id="experiment-article-section-6-heading" 
          class="heading">
            Quizzes
          </div>

          <div id="experiment-article-section-6-content" 
          class="content">
			
			<ol style="padding:30px;">
			<li>What in your own words is the principal difference between the experiment 4 on fast localization and the experiment 6 on scan matching?<br>	</li>
			
			<li>Which of the experiments 4 or 6 attempt a global localization while which of it attempts a local localization?<br>	</li>
			
			<li>Enumerate what factors could lead to a less than satisfactory performance of scan matching?</li>
			
			</ol>
			
			
          </div>

        </section>

			
		
        <section id="experiment-article-section-8">
   
          <div id="experiment-article-section-8-icon" 
          class="icon">
	    <!-- Enclose the icon image of your lab.-->
	    <img src="../images/readings.jpg" />
	  </div>

          <div id="experiment-article-section-8-heading" 
          class="heading">
            Further Readings
          </div>

          <div id="experiment-article-section-8-content" 
          class="content">
           <p><b>Papers</b> </p>
            <ul style="padding:30px;">
			<li> Feng Lu and Evangelos Milios, <b>"Robot Pose Estimation in Unknown Environments by matching 2D Range Scans" -Journal of Intelligent and Robotic Systems, 1998</b> 
              </li>
            </ul>
          </div>

        </section>

      </div>


    <!-- An article can have a sidebar that contain related 
    links and additional material (however it is kept optional 
    at this moment) -->
    <aside id="lab-article-sidebar" class="default">
      <!-- put the content that you want to appear in the 
      sidebar -->	
    </aside>


    <!-- Article footer can display related content and 
    additional links -->						
    <footer id="lab-article-footer" class="default">
      <!-- Put the content that you want to appear here -->
    </footer>

  </article>


  <!-- Links to other labs, about us page can be kept the lab 
  footer-->
<footer id="lab-footer">
<p><center>Feedback: <a href="http://virtual-labs.ac.in/feedback/">http://virtual-labs.ac.in/feedback/</a></center></p> 
<p><center>Sponsored by MHRD: <a href="http://virtual-labs.ac.in/nmeict/" >http://virtual-labs.ac.in/nmeict/</a></center></p>
<p><center>Licensing Terms: <a href="http://virtual-labs.ac.in/licensing/" >http://virtual-labs.ac.in/licensing/</a></center></p>
</footer>

</div>		

</body>
</html>
